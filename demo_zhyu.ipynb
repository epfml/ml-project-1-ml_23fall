{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "from implementations import *\n",
    "from model import *\n",
    "\n",
    "\n",
    "def get_label(data_path):\n",
    "    lbl = []\n",
    "    with open(data_path, \"r\") as f:\n",
    "        lbl = f.readline().rstrip().split(\",\")\n",
    "\n",
    "    lbl = lbl[1:]\n",
    "    l_dict = {}\n",
    "    for i, l in enumerate(lbl):\n",
    "        l_dict.update({l: i})\n",
    "    return lbl, l_dict\n",
    "\n",
    "\n",
    "def split_data(x, split_y=True):\n",
    "    indexes1 = np.where(x[:, l_dict[\"CTELNUM1\"]] == -1)\n",
    "    i1p = np.where(x[:, l_dict[\"PVTRESD2\"]] == -1)\n",
    "    indexes2 = np.where(x[:, l_dict[\"CTELENUM\"]] == -1)\n",
    "    i2p = np.where(x[:, l_dict[\"PVTRESD1\"]] == -1)\n",
    "    result1 = np.setdiff1d(i1p, indexes1)\n",
    "    result2 = np.setdiff1d(i2p, indexes2)\n",
    "    print(result1, result2)\n",
    "    x_splits = [x[indexes1], x[indexes2]]\n",
    "    if split_y:\n",
    "        y_splits = [y[indexes1], y[indexes2]]\n",
    "        return x_splits, y_splits\n",
    "    return x_splits\n",
    "\n",
    "\n",
    "def remove_irrelevant_col(x):\n",
    "    relevant_indexes = []\n",
    "    for i, col in enumerate(x.T):\n",
    "        # define the irrelevant columns: 90% of values are 1/-1\n",
    "        if np.mean(col == 1) >= 0.9 or np.mean(col == -1) >= 0.9:\n",
    "            continue\n",
    "        relevant_indexes.append(i)\n",
    "    return x[:, relevant_indexes], relevant_indexes\n",
    "\n",
    "\n",
    "def clean_data(x):\n",
    "    x_clean = x.copy()\n",
    "    for i, col in enumerate(x_clean.T):\n",
    "        med = np.median(col[col != -1])\n",
    "        # col[(col > 10 * mean_value) | (col == -1)] = mean_value\n",
    "        col[col == -1] = med\n",
    "    return x_clean\n",
    "\n",
    "\n",
    "def normalize_features(x):\n",
    "    \"\"\"\n",
    "    Normalize the features using Z-score normalization.\n",
    "    \"\"\"\n",
    "    mean = np.mean(x, axis=0)\n",
    "    std = np.std(x, axis=0)\n",
    "    standardized_x = (x - mean) / std\n",
    "    return standardized_x\n",
    "\n",
    "\n",
    "def smote_oversampling(\n",
    "    x_train, y_train, minority_class, k_neighbors, oversampling_ratio\n",
    "):\n",
    "    minority_indices = np.where(y_train == minority_class)[0]\n",
    "\n",
    "    num_synthetic_samples = int(len(minority_indices) * oversampling_ratio)\n",
    "\n",
    "    synthetic_samples = []\n",
    "\n",
    "    for _ in range(num_synthetic_samples):\n",
    "        random_minority_index = np.random.choice(minority_indices)\n",
    "        minority_sample = x_train[random_minority_index]\n",
    "\n",
    "        distances = np.linalg.norm(x_train - minority_sample, axis=1)\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        nearest_neighbors_indices = sorted_indices[1 : k_neighbors + 1]\n",
    "\n",
    "        random_neighbor_index = np.random.choice(nearest_neighbors_indices)\n",
    "        neighbor_sample = x_train[random_neighbor_index]\n",
    "\n",
    "        synthetic_sample = minority_sample + np.random.random() * (\n",
    "            neighbor_sample - minority_sample\n",
    "        )\n",
    "\n",
    "        synthetic_samples.append(synthetic_sample)\n",
    "\n",
    "    x_train_oversampled = np.vstack([x_train, np.array(synthetic_samples)])\n",
    "    y_train_oversampled = np.hstack(\n",
    "        [y_train, np.full(num_synthetic_samples, minority_class)]\n",
    "    )\n",
    "\n",
    "    return x_train_oversampled, y_train_oversampled\n",
    "\n",
    "\n",
    "def train(y, x, seed, k, d, lbd):\n",
    "    k_fold = build_k_fold(y, k, seed)\n",
    "    loss_tr, loss_te, f1_tr, f1_te, weight = cross_validation(y, x, k_fold, lbd)\n",
    "    return weight\n",
    "\n",
    "def down_sampling(\n",
    "    x_train, y_train, minority_class, downsampling_ratio\n",
    "):\n",
    "    minority_class_indices = np.where(y_train == minority_class)[0]\n",
    "    majority_class_indices = np.where(y_train != minority_class)[0]\n",
    "    num_samples = int(len(minority_class_indices) * downsampling_ratio)\n",
    "    random_majority_indices = np.random.choice(majority_class_indices, num_samples, replace=False)\n",
    "    balanced_indices = np.concatenate([minority_class_indices, random_majority_indices])\n",
    "    x_train_downsampled = x_train[balanced_indices]\n",
    "    y_train_downsampled = y_train[balanced_indices]\n",
    "    return x_train_downsampled, y_train_downsampled\n",
    "\n",
    "def train_rr(y, x, seed, k, d, lbd):\n",
    "    k_fold = build_k_fold(y, k, seed)\n",
    "    loss_tr, loss_te, f1_tr, f1_te, weight = cross_validation_rr(y, x, k_fold, lbd)\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"data/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 321)\n",
      "[nan  1.  1. ...  1.  1.  1.]\n",
      "[-1.  1.  1. ...  1.  1.  1.]\n",
      "[] []\n",
      "True\n",
      "(188720,) (188720, 202)\n"
     ]
    }
   ],
   "source": [
    "y = y_train\n",
    "print(x_train.shape)\n",
    "\n",
    "x = x_train[:, :]\n",
    "print(x[:, 9])\n",
    "x[np.isnan(x)] = -1\n",
    "print(x[:, 9])\n",
    "\n",
    "lbl, l_dict = get_label(\"data/dataset/x_train.csv\")\n",
    "\n",
    "x_splits, y_splits = split_data(x)\n",
    "x_zero, tr_idx0 = remove_irrelevant_col(x_splits[0])\n",
    "x_one, tr_idx1 = remove_irrelevant_col(x_splits[1])\n",
    "x_splits = [x_zero, x_one]\n",
    "\n",
    "x_clean_0 = clean_data(x_splits[0])\n",
    "x_clean_1 = clean_data(x_splits[1])\n",
    "x_clean = [x_clean_0, x_clean_1]\n",
    "print(not np.any(x_clean_1 == -1))\n",
    "print(y_splits[0].shape, x_clean[0].shape)\n",
    "\n",
    "x_0 = normalize_features(x_clean[0])\n",
    "x_1 = normalize_features(x_clean[1])\n",
    "x_ext_0 = poly_extension(x_0, 1)\n",
    "x_ext_1 = poly_extension(x_1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30426, 203), (30426,), (13036, 201), (13036,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#please test 0.5, 1.0, 1.5, 2.0, 2.5, 3.0 here\n",
    "x_ds_0, y_ds_0 = down_sampling(x_ext_0, y_splits[0], minority_class=1, downsampling_ratio=0.5)\n",
    "x_ds_1, y_ds_1 = down_sampling(x_ext_1, y_splits[1], minority_class=1, downsampling_ratio=0.5)\n",
    "x_ds_0.shape, y_ds_0.shape, x_ds_1.shape, y_ds_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_true, y_pred):\n",
    "    \"\"\"Compute the accuracy.\"\"\"\n",
    "    y_pred = y_pred.squeeze()\n",
    "    t1 = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    t2 = np.sum((y_true == -1) & (y_pred == -1))\n",
    "\n",
    "    return (t1 + t2) / y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample ratio:  0.5\n",
      "lambda:  1e-10\n",
      "rlg:  0.34653189048401595 0.6649798643493006 0.27554791262668765 0.7159559588279597\n",
      "rr:  0.3225099185633744 0.5873887240356083 0.25695652881003106 0.6722806010830972\n",
      "lambda:  1e-09\n",
      "rlg:  0.34653189048401595 0.6649798643493006 0.27554791262668765 0.7159559588279597\n",
      "rr:  0.3225099185633744 0.5873887240356083 0.2569523499756058 0.6722734282537747\n",
      "lambda:  1e-08\n",
      "rlg:  0.34653189048401595 0.6649798643493006 0.27554791262668765 0.7159559588279597\n",
      "rr:  0.3225183367701182 0.58740462060195 0.2569356359970078 0.6722447369364846\n",
      "lambda:  1e-07\n",
      "rlg:  0.34653189048401595 0.6649798643493006 0.27554791262668765 0.7159559588279597\n",
      "rr:  0.32249027778986106 0.5873516320474778 0.25694399271449947 0.6722590825951297\n",
      "lambda:  1e-06\n",
      "rlg:  0.34653189048401595 0.6649798643493006 0.27554791262668765 0.7159559588279597\n",
      "rr:  0.3223977177845811 0.5871767698177194 0.256890580028294 0.672208872789872\n",
      "lambda:  1e-05\n",
      "rlg:  0.34653189048401595 0.6649798643493006 0.27554791262668765 0.7159559588279597\n",
      "rr:  0.322171552660152 0.586503815175922 0.2567343623070675 0.6718574041530682\n",
      "lambda:  0.0001\n",
      "rlg:  0.34653189048401595 0.6649798643493006 0.2755428717779851 0.7159487859986372\n",
      "rr:  0.32180044699319116 0.58515260703688 0.2564926111570717 0.6712333680020084\n",
      "lambda:  0.001\n",
      "rlg:  0.3465274906986358 0.6649533700720645 0.2755176703007244 0.7159129218520245\n",
      "rr:  0.32124630209504695 0.5842094107672743 0.25625901379008603 0.6707886525840118\n",
      "lambda:  0.01\n",
      "rlg:  0.3463797891780836 0.6645347604917338 0.27527997515391783 0.7154610336047054\n",
      "rr:  0.31995660671390563 0.5814699025010598 0.2553973654084907 0.6687515690564143\n",
      "sample ratio:  1.0\n",
      "lambda:  1e-10\n",
      "rlg:  0.38015907136715393 0.7555320050869012 0.3151805673987693 0.7868593766811319\n",
      "rr:  0.38422513640279504 0.727299703264095 0.3182999133968423 0.779801312627766\n",
      "lambda:  1e-09\n",
      "rlg:  0.38015907136715393 0.7555320050869012 0.3151805673987693 0.7868593766811319\n",
      "rr:  0.38420674802584354 0.7272785078423061 0.3182928454056934 0.7797941397984435\n",
      "lambda:  1e-08\n",
      "rlg:  0.38015907136715393 0.7555320050869012 0.3151805673987693 0.7868593766811319\n",
      "rr:  0.3841192729709357 0.7272626112759644 0.3183918258551755 0.7798945594089589\n",
      "lambda:  1e-07\n",
      "rlg:  0.38015907136715393 0.7555320050869012 0.3151805673987693 0.7868593766811319\n",
      "rr:  0.38410532615200477 0.7273314963967783 0.3183615442711804 0.7798945594089589\n",
      "lambda:  1e-06\n",
      "rlg:  0.38015907136715393 0.7555320050869012 0.3151805673987693 0.7868593766811319\n",
      "rr:  0.384166188014551 0.727299703264095 0.31825550152110677 0.779786966969121\n",
      "lambda:  1e-05\n",
      "rlg:  0.38015907136715393 0.7555320050869012 0.3151805673987693 0.7868593766811319\n",
      "rr:  0.38388229393078077 0.7266320474777448 0.3183432478025393 0.7797224115052183\n",
      "lambda:  0.0001\n",
      "rlg:  0.38015396396759504 0.755526706231454 0.3151587777112043 0.7868378581931643\n",
      "rr:  0.3823980410569734 0.7246873675286138 0.31753544021054025 0.7786536599361619\n",
      "lambda:  0.001\n",
      "rlg:  0.38009912826230036 0.7554525222551929 0.3151032067821599 0.786751784241294\n",
      "rr:  0.3814502649454106 0.7235110216193302 0.3168605292780365 0.7779937596384894\n",
      "lambda:  0.01\n",
      "rlg:  0.37985410856039475 0.7549385332768123 0.31479991725469464 0.7861707850661693\n",
      "rr:  0.3800656015236483 0.720586053412463 0.314798637197519 0.7749596528350607\n",
      "sample ratio:  1.5\n",
      "lambda:  1e-10\n",
      "rlg:  0.3954507682531406 0.8033965663416702 0.3386791943409471 0.8243087185740415\n",
      "rr:  0.4110398914109042 0.793074395930479 0.35275248063069187 0.829222106659972\n",
      "lambda:  1e-09\n",
      "rlg:  0.3954507682531406 0.8033965663416702 0.3386791943409471 0.8243087185740415\n",
      "rr:  0.4110336922752089 0.7930690970750318 0.352742891317349 0.8292149338306495\n",
      "lambda:  1e-08\n",
      "rlg:  0.3954507682531406 0.8033965663416702 0.3386791943409471 0.8243087185740415\n",
      "rr:  0.4110460907335908 0.7930796947859262 0.3527269762765293 0.8291503783667468\n",
      "lambda:  1e-07\n",
      "rlg:  0.3954507682531406 0.8033965663416702 0.3386791943409471 0.8243087185740415\n",
      "rr:  0.41099898939620194 0.7930849936413734 0.3527173913043478 0.8291432055374243\n",
      "lambda:  1e-06\n",
      "rlg:  0.3954507682531406 0.8033965663416702 0.3386791943409471 0.8243087185740415\n",
      "rr:  0.4109655141215677 0.7930108096651123 0.3525830910128543 0.8291216870494567\n",
      "lambda:  1e-05\n",
      "rlg:  0.39544432495845144 0.803391267486223 0.3386791943409471 0.8243087185740415\n",
      "rr:  0.411450255236489 0.7928942348452734 0.35274975593882196 0.828798909729943\n",
      "lambda:  0.0001\n",
      "rlg:  0.395437881873727 0.8033859686307757 0.3387149028077754 0.8243087185740415\n",
      "rr:  0.40984589554476225 0.7913946587537092 0.3516293636437269 0.8277445038195316\n",
      "lambda:  0.001\n",
      "rlg:  0.3953863447534334 0.803343577787198 0.33869487774599233 0.8242369902808163\n",
      "rr:  0.4095070001196602 0.7908117846545146 0.35127127774186595 0.8272352329376322\n",
      "lambda:  0.01\n",
      "rlg:  0.39520062430903297 0.8028825773632895 0.33821470873263704 0.8236631639350142\n",
      "rr:  0.40872597759145207 0.7888777024162781 0.3476899397606348 0.8236846824229818\n",
      "sample ratio:  2.0\n",
      "lambda:  1e-10\n",
      "rlg:  0.3968158606188045 0.8297583721916066 0.35220319178377046 0.8488900046623391\n",
      "rr:  0.42194155339086625 0.8346015260703687 0.37237756638160213 0.8594484094250977\n",
      "lambda:  1e-09\n",
      "rlg:  0.3968158606188045 0.8297583721916066 0.35220319178377046 0.8488900046623391\n",
      "rr:  0.4219707772366156 0.8346068249258161 0.3723656396130933 0.8594412365957752\n",
      "lambda:  1e-08\n",
      "rlg:  0.3968158606188045 0.8297583721916066 0.35220319178377046 0.8488900046623391\n",
      "rr:  0.4219785917996963 0.8346121237812633 0.3722450025627883 0.8594412365957752\n",
      "lambda:  1e-07\n",
      "rlg:  0.3968158606188045 0.8297583721916066 0.35220319178377046 0.8488900046623391\n",
      "rr:  0.42187326395318686 0.8345697329376854 0.3721049428196176 0.8594053724491626\n",
      "lambda:  1e-06\n",
      "rlg:  0.3968158606188045 0.8297583721916066 0.35220319178377046 0.8488900046623391\n",
      "rr:  0.42190451498203635 0.8345909283594743 0.3723850712798334 0.8594771007423878\n",
      "lambda:  1e-05\n",
      "rlg:  0.39680841077630713 0.8297530733361594 0.35220319178377046 0.8488900046623391\n",
      "rr:  0.42183245976330264 0.8345856295040271 0.3717940518068436 0.8590969407882939\n",
      "lambda:  0.0001\n",
      "rlg:  0.3967935119304635 0.8297424756252649 0.3521923620933522 0.8488828318330165\n",
      "rr:  0.4207569485511531 0.8339126748622298 0.37033261118898947 0.8582362012695908\n",
      "lambda:  0.001\n",
      "rlg:  0.39680156167880476 0.8297159813480288 0.3521780565034277 0.8488469676864039\n",
      "rr:  0.42014914353219135 0.8335417549809241 0.3687884749635083 0.8573180791163074\n",
      "lambda:  0.01\n",
      "rlg:  0.3966047069404887 0.8293662568885121 0.3514880313850492 0.8482301043646666\n",
      "rr:  0.41979465968778024 0.8320103857566765 0.3669443226654976 0.8549940824158089\n",
      "sample ratio:  2.5\n",
      "lambda:  1e-10\n",
      "rlg:  0.3883002536934786 0.847959940652819 0.3624588885498254 0.8651292902485386\n",
      "rr:  0.41419777689207743 0.8598134802882578 0.38234651518461876 0.8783344690313094\n",
      "lambda:  1e-09\n",
      "rlg:  0.3883002536934786 0.847959940652819 0.3624588885498254 0.8651292902485386\n",
      "rr:  0.4142069484732402 0.859818779143705 0.3823775714545785 0.8783272962019869\n",
      "lambda:  1e-08\n",
      "rlg:  0.3883002536934786 0.847959940652819 0.3624588885498254 0.8651292902485386\n",
      "rr:  0.4141886057170693 0.8598081814328105 0.3824118225166527 0.8782986048846968\n",
      "lambda:  1e-07\n",
      "rlg:  0.3883002536934786 0.847959940652819 0.3624588885498254 0.8651292902485386\n",
      "rr:  0.4142572503874252 0.8598028825773633 0.38229830631943174 0.878355987519277\n",
      "lambda:  1e-06\n",
      "rlg:  0.3883002536934786 0.847959940652819 0.3624588885498254 0.8651292902485386\n",
      "rr:  0.4142572503874252 0.8598028825773633 0.3823358089413135 0.8783057777140193\n",
      "lambda:  1e-05\n",
      "rlg:  0.3883002536934786 0.847959940652819 0.3624588885498254 0.8651292902485386\n",
      "rr:  0.41340311349625225 0.8598346757100467 0.3823101542042479 0.8781766667862139\n",
      "lambda:  0.0001\n",
      "rlg:  0.3883002536934786 0.847959940652819 0.3624588885498254 0.8651292902485386\n",
      "rr:  0.4128980644014312 0.860009537939805 0.38190517616354935 0.877688914392282\n",
      "lambda:  0.001\n",
      "rlg:  0.3882683945775428 0.8479228486646885 0.3624161073825503 0.8650790804432809\n",
      "rr:  0.41177908656517387 0.8597551928783382 0.3807148794679967 0.8770935695585124\n",
      "lambda:  0.01\n",
      "rlg:  0.38843133499329624 0.8477267910131412 0.36227231252745773 0.8646415378546067\n",
      "rr:  0.41224372696577133 0.8588755828740992 0.3784150566051213 0.8751569056414302\n",
      "sample ratio:  3.0\n",
      "lambda:  1e-10\n",
      "rlg:  0.3755855349447255 0.8587325137770242 0.3659320477502295 0.8811318724670947\n",
      "rr:  0.3917857235460368 0.8757047477744807 0.3908074846163506 0.8956138148692752\n",
      "lambda:  1e-09\n",
      "rlg:  0.3755855349447255 0.8587325137770242 0.3659320477502295 0.8811318724670947\n",
      "rr:  0.391764339798776 0.8757100466299279 0.39084212288632175 0.8956066420399527\n",
      "lambda:  1e-08\n",
      "rlg:  0.3755855349447255 0.8587325137770242 0.3659320477502295 0.8811318724670947\n",
      "rr:  0.39172263568705756 0.8757047477744807 0.390609306996987 0.8955492594053724\n",
      "lambda:  1e-07\n",
      "rlg:  0.3755855349447255 0.8587325137770242 0.3659320477502295 0.8811318724670947\n",
      "rr:  0.39160440016604403 0.8757418397626113 0.39020920502092055 0.8954631854535021\n",
      "lambda:  1e-06\n",
      "rlg:  0.3755855349447255 0.8587325137770242 0.3659320477502295 0.8811318724670947\n",
      "rr:  0.3916000415325511 0.875805426027978 0.39012345679012345 0.8954703582828246\n",
      "lambda:  1e-05\n",
      "rlg:  0.3755855349447255 0.8587325137770242 0.3659320477502295 0.8811318724670947\n",
      "rr:  0.391487590405328 0.8760597710894447 0.3898290884718499 0.8955205680880823\n",
      "lambda:  0.0001\n",
      "rlg:  0.3755855349447255 0.8587325137770242 0.3659320477502295 0.8811318724670947\n",
      "rr:  0.38978923942924465 0.8764995760915643 0.3878377813974857 0.8948678406197325\n",
      "lambda:  0.001\n",
      "rlg:  0.37556486923130955 0.8586848240779992 0.3658825779307707 0.881081662661837\n",
      "rr:  0.38840959748262754 0.8764147944044086 0.3864355940676554 0.8943585697378331\n",
      "lambda:  0.01\n",
      "rlg:  0.37580377393784925 0.8585470538363713 0.36568160152526213 0.8806799842197754\n",
      "rr:  0.3876304801670146 0.8756570580754557 0.38503026061179957 0.8928594484094251\n",
      "sample ratio:  3.5\n",
      "lambda:  1e-10\n",
      "rlg:  0.36158566081930893 0.8671311996608733 0.36752870041263225 0.8889574292579708\n",
      "rr:  0.3569627014035192 0.8851685036032217 0.39317521327458516 0.9071405515905749\n",
      "lambda:  1e-09\n",
      "rlg:  0.36158566081930893 0.8671311996608733 0.36752870041263225 0.8889574292579708\n",
      "rr:  0.3569627014035192 0.8851685036032217 0.3931199325115996 0.9071190331026073\n",
      "lambda:  1e-08\n",
      "rlg:  0.36158566081930893 0.8671311996608733 0.36752870041263225 0.8889574292579708\n",
      "rr:  0.3570220468235364 0.8851791013141161 0.3930446194225722 0.9071118602732848\n",
      "lambda:  1e-07\n",
      "rlg:  0.36158566081930893 0.8671311996608733 0.36752870041263225 0.8889574292579708\n",
      "rr:  0.35697750341307055 0.8851949978804579 0.39332583427071616 0.9071548972492199\n",
      "lambda:  1e-06\n",
      "rlg:  0.36158566081930893 0.8671311996608733 0.36752870041263225 0.8889574292579708\n",
      "rr:  0.35650623885918 0.8852267910131412 0.3930998921858154 0.9071333787612523\n",
      "lambda:  1e-05\n",
      "rlg:  0.36158566081930893 0.8671311996608733 0.36752870041263225 0.8889574292579708\n",
      "rr:  0.3557626258101126 0.8856983891479441 0.3938042712978174 0.9073629092995732\n",
      "lambda:  0.0001\n",
      "rlg:  0.36158566081930893 0.8671311996608733 0.36752870041263225 0.8889574292579708\n",
      "rr:  0.3523215691022458 0.8866150911403137 0.3920521111579737 0.9069468851988667\n",
      "lambda:  0.001\n",
      "rlg:  0.3616463461195815 0.8671100042390844 0.367520320222195 0.8889287379406807\n",
      "rr:  0.3504066027430513 0.8865621025858414 0.38959093887484786 0.9064519599756123\n",
      "lambda:  0.01\n",
      "rlg:  0.3619076672767948 0.8669987282746927 0.36755479507862787 0.8886489975971021\n",
      "rr:  0.3503173164097915 0.8860852055955913 0.3882902464967858 0.905124986550945\n",
      "sample ratio:  4.0\n",
      "lambda:  1e-10\n",
      "rlg:  0.3497344749105885 0.8728274692666385 0.369018902679707 0.8968045045368146\n",
      "rr:  0.30878875678555967 0.8900222551928784 0.38960631567940607 0.9162572176595057\n",
      "lambda:  1e-09\n",
      "rlg:  0.3497344749105885 0.8728274692666385 0.369018902679707 0.8968045045368146\n",
      "rr:  0.3087990408312795 0.8900275540483256 0.38964976476738106 0.9162500448301832\n",
      "lambda:  1e-08\n",
      "rlg:  0.3497344749105885 0.8728274692666385 0.369018902679707 0.8968045045368146\n",
      "rr:  0.3088093255620316 0.8900328529037728 0.38921404682274247 0.9161639708783129\n",
      "lambda:  1e-07\n",
      "rlg:  0.3497344749105885 0.8728274692666385 0.369018902679707 0.8968045045368146\n",
      "rr:  0.30884507792726784 0.8900275540483256 0.3887494772061899 0.9161352795610228\n",
      "lambda:  1e-06\n",
      "rlg:  0.3497344749105885 0.8728274692666385 0.369018902679707 0.8968045045368146\n",
      "rr:  0.3084361453817939 0.8901017380245867 0.38876980185078686 0.9161424523903454\n",
      "lambda:  1e-05\n",
      "rlg:  0.3497344749105885 0.8728274692666385 0.369018902679707 0.8968045045368146\n",
      "rr:  0.3074031814215719 0.8906422212802034 0.3876066363112995 0.9160707240971201\n",
      "lambda:  0.0001\n",
      "rlg:  0.3497344749105885 0.8728274692666385 0.369018902679707 0.8968045045368146\n",
      "rr:  0.3033143167617495 0.8912886816447647 0.38561543300482287 0.9159344403399922\n",
      "lambda:  0.001\n",
      "rlg:  0.3497765136123527 0.8728115727002967 0.368937998772253 0.8967686403902019\n",
      "rr:  0.3009513417669724 0.891368164476473 0.385078219013237 0.9156977369723488\n",
      "lambda:  0.01\n",
      "rlg:  0.350033834077683 0.8727585841458245 0.36888364161091436 0.8964745543879783\n",
      "rr:  0.30220378179839474 0.8912780839338703 0.3845794634981581 0.9149230714055159\n"
     ]
    }
   ],
   "source": [
    "for s in [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]:\n",
    "    print(\"sample ratio: \", s)\n",
    "    x_ds_0, y_ds_0 = down_sampling(x_ext_0, y_splits[0], minority_class=1, downsampling_ratio=s)\n",
    "    x_ds_1, y_ds_1 = down_sampling(x_ext_1, y_splits[1], minority_class=1, downsampling_ratio=s)\n",
    "    for lbd in [1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]:\n",
    "        print(\"lambda: \", lbd)\n",
    "        lweight_0 = train(y_ds_0, x_ds_0, 1000, 5, 1, lbd)\n",
    "        lweight_1 = train(y_ds_1, x_ds_1, 1000, 5, 1, lbd)\n",
    "        rweight_0 = train_rr(y_ds_0, x_ds_0, 1000, 5, 1, lbd)\n",
    "        rweight_1 = train_rr(y_ds_1, x_ds_1, 1000, 5, 1, lbd)\n",
    "\n",
    "    # see the f1 score of train set\n",
    "        y_predict_0 = predict_labels(lweight_0, x_ext_0)\n",
    "        y_predict_1 = predict_labels(lweight_1, x_ext_1)\n",
    "        print(\"rlg: \", f1_score(y_splits[0], y_predict_0), acc(y_splits[0], y_predict_0), f1_score(y_splits[1], y_predict_1),  acc(y_splits[1], y_predict_1))\n",
    "        \n",
    "        y_predict_0 = predict_labels(rweight_0, x_ext_0)\n",
    "        y_predict_1 = predict_labels(rweight_1, x_ext_1)\n",
    "        print(\"rr: \", f1_score(y_splits[0], y_predict_0), acc(y_splits[0], y_predict_0), f1_score(y_splits[1], y_predict_1),  acc(y_splits[1], y_predict_1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
